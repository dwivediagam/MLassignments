{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "lE1up7vaJQbX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE1up7vaJQbX",
        "outputId": "c33c4dd2-7413-4d27-bcc9-1d60322d0a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "CoObhjLuJQeC",
      "metadata": {
        "id": "CoObhjLuJQeC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(7777)\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "latent_dim = 128\n",
        "epochs = 100\n",
        "\n",
        "# MNIST data loading\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "9ThQeYbdx4_W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ThQeYbdx4_W",
        "outputId": "24f6b9f1-9a60-4380-d274-4f208c67d291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "# it = iter(train_loader)\n",
        "# next(it)[0].size()\n",
        "# len(train_data)\n",
        "print(train_data[0][1])\n",
        "# plt.imshow(train_data[7], cmap = 'gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "vzacFgreJQgn",
      "metadata": {
        "id": "vzacFgreJQgn"
      },
      "outputs": [],
      "source": [
        "def random_noise_generator(batch_size, dim):\n",
        "    return torch.rand(batch_size, dim)*2 - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "_6ULl3afJQjO",
      "metadata": {
        "id": "_6ULl3afJQjO"
      },
      "outputs": [],
      "source": [
        "#Comment this if you want to run the Basic GAN instead of the DCGAN\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv0 = nn.Conv2d(1, 32, kernel_size = 3, stride = 2, padding = 1)\n",
        "        #self.conv0_bn = nn.BatchNorm2d(32)\n",
        "        self.conv0_drop = nn.Dropout2d(0.25)\n",
        "        self.conv1 = nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        #self.conv1_bn = nn.BatchNorm2d(64)\n",
        "        self.conv1_drop = nn.Dropout2d(0.25)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        #self.conv2_bn = nn.BatchNorm2d(128)\n",
        "        self.conv2_drop = nn.Dropout2d(0.25)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size = 3, stride = 2, padding = 1)\n",
        "        #self.conv3_bn = nn.BatchNorm2d(256)\n",
        "        self.conv3_drop = nn.Dropout2d(0.25)\n",
        "        self.fc = nn.Linear(12544, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "        x = F.leaky_relu(self.conv0(x), 0.2)\n",
        "        #x = self.conv0_bn(x)\n",
        "        x = self.conv0_drop(x)\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        #x = self.conv1_bn(x)\n",
        "        x = self.conv1_drop(x)\n",
        "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
        "        #x = self.conv2_bn(x)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
        "        #x = self.conv3_bn(x)\n",
        "        x = self.conv3_drop(x)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "\n",
        "        return num_features\n",
        "\n",
        "#Comment this if you want to run the Basic GAN instead of the DCGAN\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(100, 256*7*7)\n",
        "        self.trans_conv1 = nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
        "        #self.trans_conv1_bn = nn.BatchNorm2d(128)\n",
        "        self.trans_conv2 = nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        #self.trans_conv2_bn = nn.BatchNorm2d(64)\n",
        "        self.trans_conv3 = nn.ConvTranspose2d(64, 32, kernel_size = 3, stride = 1, padding = 1)\n",
        "        #self.trans_conv3_bn = nn.BatchNorm2d(32)\n",
        "        self.trans_conv4 = nn.ConvTranspose2d(32, 1, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 256, 7, 7)\n",
        "        x = F.relu(self.trans_conv1(x))\n",
        "        #x = self.trans_conv1_bn(x)\n",
        "        x = F.relu(self.trans_conv2(x))\n",
        "        #x = self.trans_conv2_bn(x)\n",
        "        x = F.relu(self.trans_conv3(x))\n",
        "        #x = self.trans_conv3_bn(x)\n",
        "        x = self.trans_conv4(x)\n",
        "        x = torch.tanh(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "xjqFyeRlwI_a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjqFyeRlwI_a",
        "outputId": "a5992422-3132-4583-d40e-200227fff34e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (conv0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (conv0_drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv1_drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2_drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (conv3_drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (fc): Linear(in_features=12544, out_features=1, bias=True)\n",
            ")\n",
            "Generator(\n",
            "  (fc): Linear(in_features=100, out_features=12544, bias=True)\n",
            "  (trans_conv1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "  (trans_conv2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (trans_conv3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (trans_conv4): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Uncomment this if you want to run the Basic GAN instead of the DCGAN\n",
        "\"\"\"\n",
        "#Creating instances of models\n",
        "D = Discriminator(input_disc, hidden_disc, output_disc)\n",
        "G = Generator(input_gen, hidden_gen, output_gen)\n",
        "\"\"\"\n",
        "\n",
        "#Comment the following 2 lines if you want to run the Basic GAN instead of the DCGAN\n",
        "D = Discriminator()\n",
        "G = Generator()\n",
        "\n",
        "#Sanity check of the model instances\n",
        "print(D)\n",
        "print(G)\n",
        "\n",
        "#Passing to the GPU\n",
        "D = D.to(device)\n",
        "G = G.to(device)\n",
        "\n",
        "D = D.float()\n",
        "G = G.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "ECilb_i5wa-f",
      "metadata": {
        "id": "ECilb_i5wa-f"
      },
      "outputs": [],
      "source": [
        "Loss = nn.BCEWithLogitsLoss()\n",
        "def discriminator_real_loss(real_out):\n",
        "    real_label = torch.ones(real_out.size()[0], 1).to(device)\n",
        "    real_loss = Loss(real_out.squeeze(), real_label.squeeze())\n",
        "    return real_loss\n",
        "\n",
        "def discriminator_fake_loss(fake_out):\n",
        "    fake_label = torch.zeros(fake_out.size()[0], 1).to(device)\n",
        "    fake_loss = Loss(fake_out.squeeze(), fake_label.squeeze())\n",
        "    return fake_loss\n",
        "\n",
        "def discriminator_loss(real_out, fake_out):\n",
        "    real_loss = discriminator_real_loss(real_out)\n",
        "    fake_loss = discriminator_fake_loss(fake_out)\n",
        "    total_loss = (real_loss + fake_loss)\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "f4yjwDqlwJCW",
      "metadata": {
        "id": "f4yjwDqlwJCW"
      },
      "outputs": [],
      "source": [
        "def generator_loss(gen_disc_out):\n",
        "    label = torch.ones(gen_disc_out.size()[0], 1).to(device)\n",
        "    gen_loss = Loss(gen_disc_out.squeeze(), label.squeeze())\n",
        "    return gen_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "IjVvBcirwoBx",
      "metadata": {
        "id": "IjVvBcirwoBx"
      },
      "outputs": [],
      "source": [
        "#Important: If using Basic GAN instead of DCGAN, go for standard values lr = 0.001 and betas = (0.9, 0.999)\n",
        "\n",
        "disc_opt = optim.Adam(D.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
        "gen_opt = optim.Adam(G.parameters(), lr = 0.0002, betas = (0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "kevQbs2Bwrmu",
      "metadata": {
        "id": "kevQbs2Bwrmu"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(D, G, disc_opt, gen_opt, train_dl, batch_size = 64, epochs = 100, gen_input_size = 100):\n",
        "\n",
        "    disc_losses = []\n",
        "    gen_losses = []\n",
        "\n",
        "    #Having a fixed sample to monitor the progress of the generator\n",
        "    sample_size = 16\n",
        "    fixed_samples = random_noise_generator(sample_size, gen_input_size)\n",
        "    fixed_samples = fixed_samples.to(device)\n",
        "\n",
        "    #Going into training mode\n",
        "    D.train()\n",
        "    G.train()\n",
        "\n",
        "    for epoch in range(epochs + 1):\n",
        "\n",
        "        disc_loss_total = 0\n",
        "        gen_loss_total = 0\n",
        "        gen_out = 0\n",
        "\n",
        "        for train_x in train_dl:\n",
        "            # print(train_x.size())\n",
        "            t_x = train_x[0].squeeze()\n",
        "            #Discriminator training\n",
        "            disc_opt.zero_grad()\n",
        "            # print(t_x.size(), train_x[0].size())\n",
        "            t_x = t_x*2 - 1          #Converting the real images to have values between -1 and 1\n",
        "            t_x = t_x.to(device)     #Passing to GPU\n",
        "            real_out = D(t_x.float())\n",
        "\n",
        "            disc_gen_in = random_noise_generator(batch_size, gen_input_size)\n",
        "            disc_gen_in = disc_gen_in.to(device)   #Passing to GPU\n",
        "\n",
        "            disc_gen_out = G(disc_gen_in.float()).detach()  #Detaching to avoid training the generator\n",
        "            fake_out = D(disc_gen_out.float())\n",
        "\n",
        "            disc_loss = discriminator_loss(real_out, fake_out)  #Loss calculation\n",
        "            disc_loss_total += disc_loss\n",
        "            disc_loss.backward()\n",
        "            disc_opt.step()\n",
        "\n",
        "            #Generator training\n",
        "            gen_opt.zero_grad()\n",
        "\n",
        "\n",
        "            gen_out = G(disc_gen_in.float())     #Feeding noise into the generator\n",
        "            gen_disc_out = D(gen_out.float())       #Passing into the discrminator\n",
        "\n",
        "            gen_loss = generator_loss(gen_disc_out)  #Generator loss calculation\n",
        "            gen_loss_total += gen_loss\n",
        "            gen_loss.backward()\n",
        "            gen_opt.step()\n",
        "\n",
        "        disc_losses.append(disc_loss_total)\n",
        "        gen_losses.append(gen_loss_total)\n",
        "\n",
        "        #Plotting samples every 5 epochs\n",
        "        if epoch%5 == 0:\n",
        "            G.eval()                    #Going into eval mode to get sample images\n",
        "            samples = G(fixed_samples.float())\n",
        "            G.train()                   #Going back into train mode\n",
        "\n",
        "            fig, axes = plt.subplots(figsize=(7,7), nrows=4, ncols=4, sharey=True, sharex=True)\n",
        "            for ax, img in zip(axes.flatten(), samples):\n",
        "               img = img.cpu().detach()\n",
        "               ax.xaxis.set_visible(False)\n",
        "               ax.yaxis.set_visible(False)\n",
        "               im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
        "\n",
        "\n",
        "        #Printing losses every epoch\n",
        "        print(\"Epoch \", epoch, \": Discriminator Loss = \", disc_loss_total/len(train_dl), \", Generator Loss = \", gen_loss_total/len(train_dl))\n",
        "\n",
        "    return disc_losses, gen_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_D2LDshLwyuQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D2LDshLwyuQ",
        "outputId": "816454a9-bc09-4b5c-c2f8-aff692063809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  0 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  1 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(50.9791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  2 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  3 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  4 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  5 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  6 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  7 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  8 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.3980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  9 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  10 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.4724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  11 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.4926, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  12 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.6100, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  13 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(51.7092, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  14 : Discriminator Loss =  tensor(3.9736e-12, device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(52.0843, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  15 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(53.5663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  16 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(53.6200, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  17 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(53.6356, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  18 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(53.7998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  19 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(53.8700, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  20 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(53.8499, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  21 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(53.9451, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  22 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(53.9254, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  23 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(54.0060, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  24 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(54.0264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  25 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(54.0778, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  26 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(54.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  27 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(54.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  28 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(54.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch  29 : Discriminator Loss =  tensor(0., device='cuda:0', grad_fn=<DivBackward0>) , Generator Loss =  tensor(54.1428, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "disc_losses, gen_losses = train(D, G, disc_opt, gen_opt, train_loader, batch_size=64, epochs=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
